{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pytest\n",
    "from bedoner.entity_extractors.bert_ner import BertEntityExtractor, create_estimator\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from spacy.tokens import Doc\n",
    "from bedoner.lang.juman import Japanese as Juman\n",
    "from spacy.strings import StringStore\n",
    "from spacy.vocab import Vocab\n",
    "from spacy_pytorch_transformers.pipeline.wordpiecer import PyTT_WordPiecer\n",
    "from bedoner.lang.mecab import Japanese\n",
    "from bedoner.wordpiecer import BertWordPiecer\n",
    "import json\n",
    "from pathlib import Path \n",
    "import shutil\n",
    "from spacy.cli import package\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"bert_ner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_package(nlp):\n",
    "    meta=nlp.meta\n",
    "    req=meta.get(\"requirements\") or []\n",
    "    req.append(\"bedoner @ git+https://github.com/PKSHATechnology/bedore-ner\")\n",
    "    nlp.meta[\"requirements\"] = req\n",
    "    \n",
    "    pkgs = Path(\"../pkgs\")\n",
    "    with tempfile.TemporaryDirectory() as tmpd:\n",
    "        nlp.to_disk(str(tmpd))\n",
    "        package(tmpd, pkgs, force=True)\n",
    "    model_name  =  meta[\"lang\"] + \"_\" + meta[\"name\"]\n",
    "    pkgd = pkgs / (model_name+ \"-\" + meta[\"version\"])\n",
    "    return pkgd, tmpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "__dir__ = Path(\".\").parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabfile = __dir__ / \"../data/Japanese_L-12_H-768_A-12_E-30_BPE/vocab.txt\"\n",
    "with vocabfile.open() as f:\n",
    "    vs = []\n",
    "    for line in f:\n",
    "        vs.append(line[:-1])\n",
    "s = StringStore(vs)\n",
    "v = Vocab(strings=s)\n",
    "nlp = Juman(v, meta={\"name\": name})\n",
    "w = BertWordPiecer(\n",
    "    v,\n",
    "    vocab_file=str(vocabfile)\n",
    ")\n",
    "w.model = w.Model(w.cfg[\"vocab_file\"])\n",
    "nlp.add_pipe(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0911 18:09:40.200305 4382737856 deprecation_wrapper.py:119] From /Users/yohei_tamura/work/bedore-ner/bedoner/entity_extractors/bert_modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0911 18:09:40.203735 4382737856 deprecation_wrapper.py:119] From /Users/yohei_tamura/work/bedore-ner/bedoner/entity_extractors/bert_ner.py:168: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0911 18:09:40.208847 4382737856 deprecation_wrapper.py:119] From /Users/yohei_tamura/work/bedore-ner/bedoner/entity_extractors/bert_ner.py:218: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W0911 18:09:40.215194 4382737856 deprecation_wrapper.py:119] From /Users/yohei_tamura/work/bedore-ner/bedoner/entity_extractors/bert_modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0911 18:09:40.217982 4382737856 deprecation_wrapper.py:119] From /Users/yohei_tamura/work/bedore-ner/bedoner/entity_extractors/bert_modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W0911 18:09:40.247230 4382737856 deprecation_wrapper.py:119] From /Users/yohei_tamura/work/bedore-ner/bedoner/entity_extractors/bert_modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
      "\n",
      "W0911 18:09:40.293100 4382737856 deprecation.py:323] From /Users/yohei_tamura/work/bedore-ner/bedoner/entity_extractors/bert_modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0911 18:09:42.176595 4382737856 deprecation_wrapper.py:119] From /Users/yohei_tamura/work/bedore-ner/bedoner/entity_extractors/bert_ner.py:241: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "W0911 18:09:42.181015 4382737856 deprecation_wrapper.py:119] From /Users/yohei_tamura/work/bedore-ner/bedoner/entity_extractors/bert_ner.py:248: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
      "\n",
      "W0911 18:09:42.713762 4382737856 deprecation.py:323] From /Users/yohei_tamura/anaconda3/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "W0911 18:09:42.836534 4382737856 deprecation.py:323] From /Users/yohei_tamura/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0911 18:09:43.096666 4382737856 deprecation.py:323] From /Users/yohei_tamura/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "W0911 18:09:43.535597 4382737856 deprecation.py:323] From /Users/yohei_tamura/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n"
     ]
    }
   ],
   "source": [
    "bert_dir = __dir__ / \"../data/Japanese_L-12_H-768_A-12_E-30_BPE\"\n",
    "model_dir = __dir__ / \"../data/bert_result_ene_0/\"\n",
    "init_checkpoint = str(bert_dir / \"bert_model.ckpt\")\n",
    "with (model_dir / \"label2id.json\").open(\"r\") as f:\n",
    "    label2id = json.load(f)\n",
    "\n",
    "bert_cfg = dict(\n",
    "    bert_dir=str(bert_dir),\n",
    "    model_dir=str(model_dir),\n",
    "    num_labels=len(label2id) + 1,\n",
    "    init_checkpoint=init_checkpoint,\n",
    "    use_one_hot_embeddings=None,\n",
    "    max_seq_length=128,\n",
    "    batch_size=10,\n",
    ")\n",
    "\n",
    "ee = BertEntityExtractor.from_nlp(nlp, label2id=label2id, **bert_cfg)\n",
    "ee.model = create_estimator(**bert_cfg)\n",
    "ee.set_values()\n",
    "ee.create_predictor()\n",
    "nlp.add_pipe(ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ＥＸＩＬＥ, ＡＴＳＵＳＨＩ, 中島美嘉, １４日, ニューヨーク)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc=nlp(\"EXILEのATSUSHIと中島美嘉が14日ニューヨーク入り\") \n",
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.to_disk(\"foo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Loaded meta.json from file\u001b[0m\n",
      "/var/folders/vc/4qw043p150b0gtkbm6rhqw9w0000gp/T/tmpmsq3q2ah/meta.json\n",
      "\u001b[38;5;2m✔ Successfully created package 'juman_bert_ner-0.0.0'\u001b[0m\n",
      "../pkgs/juman_bert_ner-0.0.0\n",
      "To build the package, run `python setup.py sdist` in this directory.\n"
     ]
    }
   ],
   "source": [
    "pkgd, tmpd = create_package(nlp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
