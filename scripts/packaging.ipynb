{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run  packaging.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# date_ruler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from bedoner.lang.mecab import Japanese\n",
    "from bedoner.entity_rulers.date import DateRuler\n",
    "import shutil\n",
    "name=\"date_ruler\"\n",
    "\n",
    "nlp = Japanese(meta={\"name\": \"date_ruler\", \"requirements\": [\"mecab-python3\", \"regex\"]})\n",
    "nlp.add_pipe(DateRuler(nlp))\n",
    "text = \"2019年11月8日に高松隆と東京タワーに行った\"\n",
    "expected = nlp(text).ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Loaded meta.json from file\u001b[0m\n",
      "/var/folders/vc/4qw043p150b0gtkbm6rhqw9w0000gp/T/tmp1gqhqedk/meta.json\n",
      "\u001b[38;5;2m✔ Successfully created package 'mecab_date_ruler-0.0.0'\u001b[0m\n",
      "/Users/yohei_tamura/work/bedore-ner/scripts/../pkgs/mecab_date_ruler-0.0.0\n",
      "To build the package, run `python setup.py sdist` in this directory.\n"
     ]
    }
   ],
   "source": [
    "pkgd, tmpd = create_package(nlp)\n",
    "nlp = spacy.load(tmpd.name)\n",
    "tmpd.cleanup()\n",
    "assert nlp(text).ents == expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# person_ruler\n",
    "\n",
    "- mecabのユーザ辞書を含める必要がありちょっと面倒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import spacy\n",
    "from bedoner.lang.mecab import Japanese\n",
    "from bedoner.entity_rulers.person import create_person_ruler\n",
    "from pathlib import Path\n",
    "from spacy.cli import package\n",
    "from shutil import copy\n",
    "\n",
    "name=\"person_ruler\"\n",
    "user_dic = os.path.expanduser(\"~/.bedoner/user.dic\")\n",
    "nlp = Japanese(meta={\"tokenizer\": {\"userdic\": user_dic,\"assets\": \"./jinmei/\"}, \"name\":name,\"requirements\": [\"mecab-python3\", \"regex\"] })\n",
    "nlp.add_pipe(create_person_ruler(nlp))\n",
    "expected = nlp(text).ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Loaded meta.json from file\u001b[0m\n",
      "/var/folders/vc/4qw043p150b0gtkbm6rhqw9w0000gp/T/tmpn0sko71z/meta.json\n",
      "\u001b[38;5;2m✔ Successfully created package 'mecab_person_ruler-0.0.0'\u001b[0m\n",
      "/Users/yohei_tamura/work/bedore-ner/scripts/../pkgs/mecab_person_ruler-0.0.0\n",
      "To build the package, run `python setup.py sdist` in this directory.\n"
     ]
    }
   ],
   "source": [
    "pkgd, tmpd = create_package(nlp)\n",
    "nlp=spacy.load(tmpd.name)\n",
    "tmpd.cleanup()\n",
    "assert nlp(text).ents == expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# entity_ruler\n",
    "\n",
    "- 上の二つの組みわせ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from bedoner.entity_rulers.person import create_person_ruler\n",
    "from bedoner.entity_rulers.date import DateRuler\n",
    "\n",
    "name=\"entity_ruler\"\n",
    "nlp = Japanese(meta={\"tokenizer\": {\"userdic\": user_dic,\"assets\": \"./jinmei/\"}, \"name\":name, \"requirements\": [\"mecab-python3\", \"regex\"]})\n",
    "nlp.add_pipe(DateRuler(nlp))\n",
    "nlp.add_pipe(create_person_ruler(nlp))\n",
    "expected = nlp(text).ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Loaded meta.json from file\u001b[0m\n",
      "/var/folders/vc/4qw043p150b0gtkbm6rhqw9w0000gp/T/tmp0h6t85_r/meta.json\n",
      "\u001b[38;5;2m✔ Successfully created package 'mecab_entity_ruler-0.0.0'\u001b[0m\n",
      "/Users/yohei_tamura/work/bedore-ner/scripts/../pkgs/mecab_entity_ruler-0.0.0\n",
      "To build the package, run `python setup.py sdist` in this directory.\n"
     ]
    }
   ],
   "source": [
    "pkgd,tmpd=create_package(nlp)\n",
    "nlp = spacy.load(tmpd.name) \n",
    "tmpd.cleanup()\n",
    "assert nlp(text).ents == expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# knp entity extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from bedoner.lang.knp import Japanese\n",
    "from bedoner.entity_extractors.knp import KnpEntityExtractor\n",
    "\n",
    "name = \"entity_extractor\"\n",
    "nlp = Japanese(meta={\"name\": name, \"requirements\": [\"regex\", \"pyknp\"]})\n",
    "p = nlp.create_pipe(\"knp_entity_extractor\")\n",
    "nlp.add_pipe(p)\n",
    "expected = nlp(text).ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Loaded meta.json from file\u001b[0m\n",
      "/var/folders/vc/4qw043p150b0gtkbm6rhqw9w0000gp/T/tmp14n_3cqe/meta.json\n",
      "\u001b[38;5;2m✔ Successfully created package 'knp_entity_extractor-0.0.0'\u001b[0m\n",
      "/Users/yohei_tamura/work/bedore-ner/scripts/../pkgs/knp_entity_extractor-0.0.0\n",
      "To build the package, run `python setup.py sdist` in this directory.\n"
     ]
    }
   ],
   "source": [
    "pkgd, tmpd=create_package(nlp)\n",
    "nlp = spacy.load(tmpd.name)\n",
    "tmpd.cleanup()\n",
    "assert nlp(text).ents == expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from bedoner.entity_extractors.bert_ner import BertEntityExtractor, create_estimator\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from spacy.tokens import Doc\n",
    "from bedoner.lang.juman import Japanese as Juman\n",
    "from spacy.strings import StringStore\n",
    "from spacy.vocab import Vocab\n",
    "from spacy_pytorch_transformers.pipeline.wordpiecer import PyTT_WordPiecer\n",
    "from bedoner.lang.mecab import Japanese\n",
    "from bedoner.wordpiecer import BertWordPiecer\n",
    "import json\n",
    "from pathlib import Path \n",
    "import shutil\n",
    "from spacy.cli import package\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"bert_ner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_package(nlp):\n",
    "    meta=nlp.meta\n",
    "    req=meta.get(\"requirements\") or []\n",
    "    req.append(\"bedoner @ git+https://github.com/PKSHATechnology/bedore-ner\")\n",
    "    nlp.meta[\"requirements\"] = req\n",
    "    \n",
    "    pkgs = Path(\"../pkgs\")\n",
    "    with tempfile.TemporaryDirectory() as tmpd:\n",
    "        nlp.to_disk(str(tmpd))\n",
    "        package(tmpd, pkgs, force=True)\n",
    "    model_name  =  meta[\"lang\"] + \"_\" + meta[\"name\"]\n",
    "    pkgd = pkgs / (model_name+ \"-\" + meta[\"version\"])\n",
    "    return pkgd, tmpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "__dir__ = Path(\".\").parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabfile = __dir__ / \"../data/Japanese_L-12_H-768_A-12_E-30_BPE/vocab.txt\"\n",
    "with vocabfile.open() as f:\n",
    "    vs = []\n",
    "    for line in f:\n",
    "        vs.append(line[:-1])\n",
    "s = StringStore(vs)\n",
    "v = Vocab(strings=s)\n",
    "nlp = Juman(v, meta={\"name\": name})\n",
    "w = BertWordPiecer(\n",
    "    v,\n",
    "    vocab_file=str(vocabfile)\n",
    ")\n",
    "w.model = w.Model(w.cfg[\"vocab_file\"])\n",
    "nlp.add_pipe(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0911 18:09:40.200305 4382737856 deprecation_wrapper.py:119] From /Users/yohei_tamura/work/bedore-ner/bedoner/entity_extractors/bert_modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0911 18:09:40.203735 4382737856 deprecation_wrapper.py:119] From /Users/yohei_tamura/work/bedore-ner/bedoner/entity_extractors/bert_ner.py:168: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0911 18:09:40.208847 4382737856 deprecation_wrapper.py:119] From /Users/yohei_tamura/work/bedore-ner/bedoner/entity_extractors/bert_ner.py:218: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W0911 18:09:40.215194 4382737856 deprecation_wrapper.py:119] From /Users/yohei_tamura/work/bedore-ner/bedoner/entity_extractors/bert_modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0911 18:09:40.217982 4382737856 deprecation_wrapper.py:119] From /Users/yohei_tamura/work/bedore-ner/bedoner/entity_extractors/bert_modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W0911 18:09:40.247230 4382737856 deprecation_wrapper.py:119] From /Users/yohei_tamura/work/bedore-ner/bedoner/entity_extractors/bert_modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
      "\n",
      "W0911 18:09:40.293100 4382737856 deprecation.py:323] From /Users/yohei_tamura/work/bedore-ner/bedoner/entity_extractors/bert_modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0911 18:09:42.176595 4382737856 deprecation_wrapper.py:119] From /Users/yohei_tamura/work/bedore-ner/bedoner/entity_extractors/bert_ner.py:241: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "W0911 18:09:42.181015 4382737856 deprecation_wrapper.py:119] From /Users/yohei_tamura/work/bedore-ner/bedoner/entity_extractors/bert_ner.py:248: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
      "\n",
      "W0911 18:09:42.713762 4382737856 deprecation.py:323] From /Users/yohei_tamura/anaconda3/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "W0911 18:09:42.836534 4382737856 deprecation.py:323] From /Users/yohei_tamura/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0911 18:09:43.096666 4382737856 deprecation.py:323] From /Users/yohei_tamura/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "W0911 18:09:43.535597 4382737856 deprecation.py:323] From /Users/yohei_tamura/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n"
     ]
    }
   ],
   "source": [
    "bert_dir = __dir__ / \"../data/Japanese_L-12_H-768_A-12_E-30_BPE\"\n",
    "model_dir = __dir__ / \"../data/bert_result_ene_0/\"\n",
    "init_checkpoint = str(bert_dir / \"bert_model.ckpt\")\n",
    "with (model_dir / \"label2id.json\").open(\"r\") as f:\n",
    "    label2id = json.load(f)\n",
    "\n",
    "bert_cfg = dict(\n",
    "    bert_dir=str(bert_dir),\n",
    "    model_dir=str(model_dir),\n",
    "    num_labels=len(label2id) + 1,\n",
    "    init_checkpoint=init_checkpoint,\n",
    "    use_one_hot_embeddings=None,\n",
    "    max_seq_length=128,\n",
    "    batch_size=10,\n",
    ")\n",
    "\n",
    "ee = BertEntityExtractor.from_nlp(nlp, label2id=label2id, **bert_cfg)\n",
    "ee.model = create_estimator(**bert_cfg)\n",
    "ee.set_values()\n",
    "ee.create_predictor()\n",
    "nlp.add_pipe(ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected=nlp(text).ents\n",
    "pkgd, tmpd = create_package(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Loaded meta.json from file\u001b[0m\n",
      "/var/folders/vc/4qw043p150b0gtkbm6rhqw9w0000gp/T/tmp14n_3cqe/meta.json\n",
      "\u001b[38;5;2m✔ Successfully created package 'knp_entity_extractor-0.0.0'\u001b[0m\n",
      "/Users/yohei_tamura/work/bedore-ner/scripts/../pkgs/knp_entity_extractor-0.0.0\n",
      "To build the package, run `python setup.py sdist` in this directory.\n"
     ]
    }
   ],
   "source": [
    "pkgd, tmpd=create_package(nlp)\n",
    "nlp = spacy.load(tmpd.name)\n",
    "tmpd.cleanup()\n",
    "assert nlp(text).ents == expected"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
