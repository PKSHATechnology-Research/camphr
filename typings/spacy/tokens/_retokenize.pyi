from typing import Any, Dict, List

from spacy.tokens.doc import Doc

from .span import Span
from .token import Token

class Retokenizer:
    def __init__(self, doc: Doc) -> None: ...
    def __enter__(self) -> "Retokenizer": ...
    def __exit__(self, *args): ...
    def merge(self, span: Span, attrs: Dict[str, Any] = {}) -> None: ...
    def split(self, token: Token, orths: List[str], heads: List[Token], attrs: Dict[str, Any] = {}) -> None: ...
