"""
This type stub file was generated by pyright.
"""

import plac
import contextlib
from pathlib import Path
from typing import Any, Optional
@plac.annotations(
    lang=("Model language", "positional", None, str),
    output_path=("Output directory to store model in", "positional", None, Path),
    train_path=("Location of JSON-formatted training data", "positional", None, Path),
    dev_path=("Location of JSON-formatted development data", "positional", None, Path),
    raw_text=(
        "Path to jsonl file with unlabelled text documents.",
        "option",
        "rt",
        Path,
    ),
    base_model=("Name of model to update (optional)", "option", "b", str),
    pipeline=("Comma-separated names of pipeline components", "option", "p", str),
    vectors=("Model to load vectors from", "option", "v", str),
    n_iter=("Number of iterations", "option", "n", int),
    n_early_stopping=(
        "Maximum number of training epochs without dev accuracy improvement",
        "option",
        "ne",
        int,
    ),
    n_examples=("Number of examples", "option", "ns", int),
    use_gpu=("Use GPU", "option", "g", int),
    version=("Model version", "option", "V", str),
    meta_path=("Optional path to meta.json to use as base.", "option", "m", Path),
    init_tok2vec=(
        "Path to pretrained weights for the token-to-vector parts of the models. See 'spacy pretrain'. Experimental.",
        "option",
        "t2v",
        Path,
    ),
    parser_multitasks=(
        "Side objectives for parser CNN, e.g. 'dep' or 'dep,tag'",
        "option",
        "pt",
        str,
    ),
    entity_multitasks=(
        "Side objectives for NER CNN, e.g. 'dep' or 'dep,tag'",
        "option",
        "et",
        str,
    ),
    noise_level=("Amount of corruption for data augmentation", "option", "nl", float),
    orth_variant_level=(
        "Amount of orthography variation for data augmentation",
        "option",
        "ovl",
        float,
    ),
    eval_beam_widths=("Beam widths to evaluate, e.g. 4,8", "option", "bw", str),
    gold_preproc=("Use gold preprocessing", "flag", "G", bool),
    learn_tokens=("Make parser learn gold-standard tokenization", "flag", "T", bool),
    textcat_multilabel=(
        "Textcat classes aren't mutually exclusive (multilabel)",
        "flag",
        "TML",
        bool,
    ),
    textcat_arch=("Textcat model architecture", "option", "ta", str),
    textcat_positive_label=(
        "Textcat positive label for binary classes with two labels",
        "option",
        "tpl",
        str,
    ),
    verbose=("Display more information for debug", "flag", "VV", bool),
    debug=("Run data diagnostics before training", "flag", "D", bool),
)
def train(
    lang,
    output_path,
    train_path,
    dev_path,
    raw_text: Optional[Any] = ...,
    base_model: Optional[Any] = ...,
    pipeline=...,
    vectors: Optional[Any] = ...,
    n_iter=...,
    n_early_stopping: Optional[Any] = ...,
    n_examples=...,
    use_gpu=...,
    version=...,
    meta_path: Optional[Any] = ...,
    init_tok2vec: Optional[Any] = ...,
    parser_multitasks=...,
    entity_multitasks=...,
    noise_level=...,
    orth_variant_level=...,
    eval_beam_widths=...,
    gold_preproc: bool = ...,
    learn_tokens: bool = ...,
    textcat_multilabel: bool = ...,
    textcat_arch=...,
    textcat_positive_label: Optional[Any] = ...,
    verbose: bool = ...,
    debug: bool = ...,
):
    """
    Train or update a spaCy model. Requires data to be formatted in spaCy's
    JSON format. To convert data from other formats, use the `spacy convert`
    command.
    """
    ...

def _score_for_model(meta):
    """ Returns mean score between tasks in pipeline that can be used for early stopping. """
    ...

@contextlib.contextmanager
def _create_progress_bar(total): ...
def _load_vectors(nlp, vectors): ...
def _load_pretrained_tok2vec(nlp, loc):
    """Load pretrained weights for the 'token-to-vector' part of the component
    models, which is typically a CNN. See 'spacy pretrain'. Experimental.
    """
    ...

def _collate_best_model(meta, output_path, components): ...
def _find_best(experiment_dir, component): ...
def _get_metrics(component): ...
def _configure_training_output(pipeline, use_gpu, has_beam_widths): ...
def _get_progress(
    itn,
    losses,
    dev_scores,
    output_stats,
    beam_width: Optional[Any] = ...,
    cpu_wps=...,
    gpu_wps=...,
): ...
