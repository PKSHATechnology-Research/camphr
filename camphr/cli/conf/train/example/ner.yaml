model:
    lang:
        name: en
    pretrained: bert-base-cased
    ner_label: ~/irex.json
train:
    data:
        path: ~/train.jsonl
        ndata: -1
        val_size: 0.1
    niter: 10
    nbatch: 16
    optimizer:
        class: transformers.optimization.AdamW
        params:
            lr: 2e-5
            eps: 1e-8
    scheduler:
        class: transformers.optimization.get_linear_schedule_with_warmup
        params:
            num_warmup_steps: 10
            num_training_steps: 10
